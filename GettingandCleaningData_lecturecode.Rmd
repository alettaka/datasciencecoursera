---
title: "GettingandCleaningData_lecturecode"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Downloading files

Here is an example checking for a "data" directory and creating it if it doesn't exist
```{r}
if (!file.exists("data")) {
dir.create("data")}
```

```{r}
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "./data/cameras.csv", method = "curl")
list.files("./data")
dateDownloaded <- date()
dateDownloaded
```
If the url starts with https on Mac you may need to set method="curl" - I don't think this is needed on linux? - safer to simply include it
This link doesn't work anymore, I can still download the data, but not a fixed link that I can paste in the code above, have saved my manual download with this name to proceed...

## Reading local flat files

```{r}
cameraData <- read.table("./data/cameras.csv", sep = ",", header = TRUE)
head (cameraData)
```
Don't understand that error, but the csv specific import works:

```{r}
cameraData <- read.csv("./data/cameras.csv")
head (cameraData)
```

## Reading XML

```{r}
library (XML)
fileUrl <- "http://www.w3schools.com/xml/simple.xml" 
# doc <- xmlTreeParse(fileUrl, useInternal=TRUE) 
```
I commented out the last line because of this error: Unknown IO error failed to load external entity 
workaround from the forum:
Much of this lecture is broken as it was recorded in 2013(!!). There's a pinned discussion on how to get the NFL data. For the simple XML w3schools exercise, you can use xml2 package to grab the xml from url:
```{r}
library (XML) 
library(xml2)

fileUrl <- "https://www.w3schools.com/xml/simple.xml" 
doc <- xmlParse(read_xml(fileUrl))

rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
```
Directly access parts of the XML document
```{r}
rootNode[[1]]
rootNode[[1]][[1]]
```
Programmatically extract parts of the file, get the items on the menu and prices 
```{r}
xmlSApply (rootNode, xmlValue)
xpathSApply (rootNode, "//name" ,xmlValue)
xpathSApply (rootNode, "//price" ,xmlValue)
```
Extract content by attributes - this example doesn't work anymore, I updated the link below with the link that the old link redirects too, but the content is no longer in xml

```{r}
fileUrl <- "https://www.espn.com/nfl/team/_/name/bal/baltimore-ravens" 
doc <- htmlTreeParse(fileUrl,useInternal=TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
teams <- xpathSApply(doc,"//li[@class='team-name']",xmlValue)
scores
teams
```
Short Introduction to XML: http://www.omegahat.net/RSXML/shortIntro.pdf
Long Introduction to XML: http://www.omegahat.net/RSXML/Tour.pdf

## Reading JSON

Reading data from JSON {jsonlite package}, nested objects in JSON
```{r}
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos") 
names(jsonData)
names(jsonData$owner)
names(jsonData$owner$login)
```
Writing data frames to JSON, Convert back to JSON
```{r}
myjson <- toJSON(iris, pretty=TRUE) 
cat(myjson)
iris2 <- fromJSON(myjson) 
head(iris2)
```
http://www.json.org/
http://www.r-bloggers.com/new-package-jsonlite-a-smarter-json

## The data.table Package

Create data tables just like data frames
```{r}

library(data.table) 
DF = data.frame(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9)) 
head(DF, 3)

DT = data.table(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9)) 
head(DT, 3)
```
See all the data tables in memory 
```{r}
tables()
```

Subsetting rows
```{r}
DT[2,]
DT[DT$y=="a" , ]
DT[c(2,3)]
```

Column subsetting in data.table

* The subsetting function is modified for data.table 
* The argument you pass after the comma is called an "expression"
* In R an expression is a collection of statements enclosed in curley brackets
```{r}
{
  x=1
  y=2
}  
k = {print(10); 5}

print (k)
```
Calculating values for variables with expressions
```{r}
DT[,list(mean(x),sum(z))]
DT[,table(y)]
```
Adding new columns
```{r}
DT[,w:=z^2]
DT2 <- DT # ! assigning DT to DT2, is not making a copy of the datatable
DT[, y:= 2]  # so when you change DT, DT2 is changed as well
head(DT,n=3)
head(DT2,n=3)
```

Multiple operations 
```{r}
DT[,m:= {tmp <- (x+z); log2(tmp+5)}]
DT
```

plyr like operations 
```{r}
DT[, a:=x>0]
DT[ ,b:= mean(x+w), by=a]
DT
```
Special variables
.N returns the total number of observations of each group.
```{r}
set.seed(123); 
DT <- data.table(x=sample(letters[1:3], 1E5, TRUE))
DT[, .N, by=x]
```
Keys
```{r}
DT <- data.table(x=rep(c("a","b","c"),each=100), y=rnorm(300)) 
setkey(DT, x) 
DT['a']
```
Joins
```{r}
DT1 <- data.table(x=c('a', 'a', 'b', 'dtl'), y=1:4) 
DT2 <- data.table(x=c('a', 'b', 'dt2'), z=5:7) 
setkey(DT1, x); setkey(DT2, x)
merge (DT1, DT2)
```

Fast reading
```{r}
big_df <- data.frame(x=rnorm(1E6), y=rnorm(1E6)) 
file <- tempfile()
write.table(big_df, file=file, row.names=FALSE, col.names=TRUE, sep="\t", quote=FALSE) 
system.time(fread(file))
```

```{r}
system.time(read.table(file, header=TRUE, sep="\t"))
```

Summary and further reading
- The latest development version contains new functions like melt and dcast for data.tables - https://github.com/Rdatatable/data.table (link updated)

Here is a list of differences between data.table and data.frame
- http://stackoverflow.com/questions/13618488/what-you-can-do-with-data-frame-that-you-cant-in-data-table







